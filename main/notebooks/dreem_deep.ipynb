{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dreem Project - Deep Learning - TF & Keras - Basile NOUVELLET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8909690045639871536\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9604628808204645324\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16661797590608488637\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11330115994\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6979578593716129426\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = pd.read_hdf('df_train_final.h5', 'df_train_final')\n",
    "\n",
    "var_to_pred = 'SO'\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train_final.loc[:, df_train_final.columns != var_to_pred],\n",
    "                                                  df_train_final[var_to_pred],\n",
    "                                                  test_size=0.10,\n",
    "                                                  random_state=0,\n",
    "                                                  stratify=df_train_final[var_to_pred])\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_val = pd.DataFrame(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pso</th>\n",
       "      <th>mean_amp_pso</th>\n",
       "      <th>mean_dur_pso</th>\n",
       "      <th>amp_cso</th>\n",
       "      <th>dur_cso</th>\n",
       "      <th>time_since_sleep</th>\n",
       "      <th>time_in_ds</th>\n",
       "      <th>time_in_ls</th>\n",
       "      <th>time_in_rs</th>\n",
       "      <th>time_in_ws</th>\n",
       "      <th>...</th>\n",
       "      <th>wawelets_86</th>\n",
       "      <th>wawelets_87</th>\n",
       "      <th>wawelets_88</th>\n",
       "      <th>wawelets_89</th>\n",
       "      <th>wawelets_90</th>\n",
       "      <th>wawelets_91</th>\n",
       "      <th>wawelets_92</th>\n",
       "      <th>wawelets_93</th>\n",
       "      <th>wawelets_94</th>\n",
       "      <th>wawelets_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237.0</td>\n",
       "      <td>152.658761</td>\n",
       "      <td>341.523207</td>\n",
       "      <td>128.017491</td>\n",
       "      <td>429.0</td>\n",
       "      <td>11379.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>...</td>\n",
       "      <td>457</td>\n",
       "      <td>-1.508171</td>\n",
       "      <td>-0.600457</td>\n",
       "      <td>0.605929</td>\n",
       "      <td>1.524894</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>1.006676</td>\n",
       "      <td>1.013396</td>\n",
       "      <td>0.740114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176.0</td>\n",
       "      <td>146.883435</td>\n",
       "      <td>338.039773</td>\n",
       "      <td>119.130849</td>\n",
       "      <td>196.0</td>\n",
       "      <td>6721.0</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>...</td>\n",
       "      <td>453</td>\n",
       "      <td>-1.302524</td>\n",
       "      <td>-0.578372</td>\n",
       "      <td>0.553759</td>\n",
       "      <td>1.361592</td>\n",
       "      <td>-0.032801</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.845156</td>\n",
       "      <td>0.714289</td>\n",
       "      <td>0.661250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>456.0</td>\n",
       "      <td>152.376541</td>\n",
       "      <td>335.629386</td>\n",
       "      <td>164.292580</td>\n",
       "      <td>417.0</td>\n",
       "      <td>26832.0</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>7440.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>462</td>\n",
       "      <td>-1.774095</td>\n",
       "      <td>-0.736667</td>\n",
       "      <td>0.757092</td>\n",
       "      <td>1.778728</td>\n",
       "      <td>0.016140</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>1.099851</td>\n",
       "      <td>1.209672</td>\n",
       "      <td>0.872444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>139.720772</td>\n",
       "      <td>336.285714</td>\n",
       "      <td>159.237082</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>-1.514035</td>\n",
       "      <td>-0.667986</td>\n",
       "      <td>0.661924</td>\n",
       "      <td>1.535148</td>\n",
       "      <td>-0.005341</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.961756</td>\n",
       "      <td>0.924975</td>\n",
       "      <td>0.773179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>140.649432</td>\n",
       "      <td>349.875000</td>\n",
       "      <td>130.184278</td>\n",
       "      <td>297.0</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>452</td>\n",
       "      <td>-1.425063</td>\n",
       "      <td>-0.590922</td>\n",
       "      <td>0.636247</td>\n",
       "      <td>1.404894</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.002912</td>\n",
       "      <td>0.872183</td>\n",
       "      <td>0.760704</td>\n",
       "      <td>0.701210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pso  mean_amp_pso  mean_dur_pso     amp_cso  dur_cso  time_since_sleep  \\\n",
       "0    237.0    152.658761    341.523207  128.017491    429.0           11379.0   \n",
       "1    176.0    146.883435    338.039773  119.130849    196.0            6721.0   \n",
       "2    456.0    152.376541    335.629386  164.292580    417.0           26832.0   \n",
       "3     21.0    139.720772    336.285714  159.237082    407.0            1289.0   \n",
       "4     72.0    140.649432    349.875000  130.184278    297.0            2262.0   \n",
       "\n",
       "   time_in_ds  time_in_ls  time_in_rs  time_in_ws  ...  wawelets_86  \\\n",
       "0      2730.0      3780.0         0.0       480.0  ...          457   \n",
       "1      2580.0      2100.0         0.0       480.0  ...          453   \n",
       "2      3240.0      7440.0      2130.0       750.0  ...          462   \n",
       "3         0.0        60.0         0.0       450.0  ...          460   \n",
       "4       630.0       960.0         0.0       450.0  ...          452   \n",
       "\n",
       "   wawelets_87  wawelets_88  wawelets_89  wawelets_90  wawelets_91  \\\n",
       "0    -1.508171    -0.600457     0.605929     1.524894     0.011170   \n",
       "1    -1.302524    -0.578372     0.553759     1.361592    -0.032801   \n",
       "2    -1.774095    -0.736667     0.757092     1.778728     0.016140   \n",
       "3    -1.514035    -0.667986     0.661924     1.535148    -0.005341   \n",
       "4    -1.425063    -0.590922     0.636247     1.404894     0.001580   \n",
       "\n",
       "   wawelets_92  wawelets_93  wawelets_94  wawelets_95  \n",
       "0    -0.000105     1.006676     1.013396     0.740114  \n",
       "1     0.001091     0.845156     0.714289     0.661250  \n",
       "2    -0.001139     1.099851     1.209672     0.872444  \n",
       "3     0.000916     0.961756     0.924975     0.773179  \n",
       "4    -0.002912     0.872183     0.760704     0.701210  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_pso',\n",
       " 'mean_amp_pso',\n",
       " 'mean_dur_pso',\n",
       " 'amp_cso',\n",
       " 'dur_cso',\n",
       " 'time_since_sleep',\n",
       " 'time_in_ds',\n",
       " 'time_in_ls',\n",
       " 'time_in_rs',\n",
       " 'time_in_ws',\n",
       " 'mean',\n",
       " 'max',\n",
       " 'min',\n",
       " 'perm_entropy',\n",
       " 'svd_entropy',\n",
       " 'higuchi_fd',\n",
       " 'detrended_fluctuation',\n",
       " 'fft_0',\n",
       " 'fft_1',\n",
       " 'fft_2',\n",
       " 'fft_3',\n",
       " 'fft_4',\n",
       " 'fft_5',\n",
       " 'fft_6',\n",
       " 'fft_7',\n",
       " 'fft_8',\n",
       " 'fft_9',\n",
       " 'fft_10',\n",
       " 'fft_11',\n",
       " 'fft_12',\n",
       " 'fft_13',\n",
       " 'fft_14',\n",
       " 'fft_15',\n",
       " 'fft_16',\n",
       " 'fft_17',\n",
       " 'fft_18',\n",
       " 'fft_19',\n",
       " 'fft_20',\n",
       " 'fft_21',\n",
       " 'fft_22',\n",
       " 'fft_23',\n",
       " 'fft_24',\n",
       " 'fft_25',\n",
       " 'fft_26',\n",
       " 'fft_27',\n",
       " 'fft_28',\n",
       " 'fft_29',\n",
       " 'fft_30',\n",
       " 'fft_31',\n",
       " 'fft_32',\n",
       " 'fft_33',\n",
       " 'fft_34',\n",
       " 'fft_35',\n",
       " 'fft_36',\n",
       " 'fft_37',\n",
       " 'fft_38',\n",
       " 'fft_39',\n",
       " 'fft_40',\n",
       " 'fft_41',\n",
       " 'fft_42',\n",
       " 'fft_43',\n",
       " 'fft_44',\n",
       " 'fft_45',\n",
       " 'fft_46',\n",
       " 'fft_47',\n",
       " 'fft_48',\n",
       " 'fft_49',\n",
       " 'fft_50',\n",
       " 'fft_51',\n",
       " 'fft_52',\n",
       " 'fft_53',\n",
       " 'fft_54',\n",
       " 'fft_55',\n",
       " 'fft_56',\n",
       " 'fft_57',\n",
       " 'fft_58',\n",
       " 'fft_59',\n",
       " 'fft_60',\n",
       " 'fft_61',\n",
       " 'fft_62',\n",
       " 'fft_63',\n",
       " 'curr_sleep_stage_2.0',\n",
       " 'curr_sleep_stage_3.0',\n",
       " 'slow_o',\n",
       " 'SO',\n",
       " 'wawelets_0',\n",
       " 'wawelets_1',\n",
       " 'wawelets_2',\n",
       " 'wawelets_3',\n",
       " 'wawelets_4',\n",
       " 'wawelets_5',\n",
       " 'wawelets_6',\n",
       " 'wawelets_7',\n",
       " 'wawelets_8',\n",
       " 'wawelets_9',\n",
       " 'wawelets_10',\n",
       " 'wawelets_11',\n",
       " 'wawelets_12',\n",
       " 'wawelets_13',\n",
       " 'wawelets_14',\n",
       " 'wawelets_15',\n",
       " 'wawelets_16',\n",
       " 'wawelets_17',\n",
       " 'wawelets_18',\n",
       " 'wawelets_19',\n",
       " 'wawelets_20',\n",
       " 'wawelets_21',\n",
       " 'wawelets_22',\n",
       " 'wawelets_23',\n",
       " 'wawelets_24',\n",
       " 'wawelets_25',\n",
       " 'wawelets_26',\n",
       " 'wawelets_27',\n",
       " 'wawelets_28',\n",
       " 'wawelets_29',\n",
       " 'wawelets_30',\n",
       " 'wawelets_31',\n",
       " 'wawelets_32',\n",
       " 'wawelets_33',\n",
       " 'wawelets_34',\n",
       " 'wawelets_35',\n",
       " 'wawelets_36',\n",
       " 'wawelets_37',\n",
       " 'wawelets_38',\n",
       " 'wawelets_39',\n",
       " 'wawelets_40',\n",
       " 'wawelets_41',\n",
       " 'wawelets_42',\n",
       " 'wawelets_43',\n",
       " 'wawelets_44',\n",
       " 'wawelets_45',\n",
       " 'wawelets_46',\n",
       " 'wawelets_47',\n",
       " 'wawelets_48',\n",
       " 'wawelets_49',\n",
       " 'wawelets_50',\n",
       " 'wawelets_51',\n",
       " 'wawelets_52',\n",
       " 'wawelets_53',\n",
       " 'wawelets_54',\n",
       " 'wawelets_55',\n",
       " 'wawelets_56',\n",
       " 'wawelets_57',\n",
       " 'wawelets_58',\n",
       " 'wawelets_59',\n",
       " 'wawelets_60',\n",
       " 'wawelets_61',\n",
       " 'wawelets_62',\n",
       " 'wawelets_63',\n",
       " 'wawelets_64',\n",
       " 'wawelets_65',\n",
       " 'wawelets_66',\n",
       " 'wawelets_67',\n",
       " 'wawelets_68',\n",
       " 'wawelets_69',\n",
       " 'wawelets_70',\n",
       " 'wawelets_71',\n",
       " 'wawelets_72',\n",
       " 'wawelets_73',\n",
       " 'wawelets_74',\n",
       " 'wawelets_75',\n",
       " 'wawelets_76',\n",
       " 'wawelets_77',\n",
       " 'wawelets_78',\n",
       " 'wawelets_79',\n",
       " 'wawelets_80',\n",
       " 'wawelets_81',\n",
       " 'wawelets_82',\n",
       " 'wawelets_83',\n",
       " 'wawelets_84',\n",
       " 'wawelets_85',\n",
       " 'wawelets_86',\n",
       " 'wawelets_87',\n",
       " 'wawelets_88',\n",
       " 'wawelets_89',\n",
       " 'wawelets_90',\n",
       " 'wawelets_91',\n",
       " 'wawelets_92',\n",
       " 'wawelets_93',\n",
       " 'wawelets_94',\n",
       " 'wawelets_95']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(df_train_final.columns)\n",
    "\n",
    "equations = {\n",
    "     'base_model': {'predictors': features[0:13]},\n",
    "     'entropy_fft': {'predictors': features[0:81]},\n",
    "     'dummy_variables_only': {'predictors': features[0:11] + features[81:83]},\n",
    "     'dummy_variables': {'predictors': features[0:83]},\n",
    "     'fft_wawelets' : {'predictors': features[0:81] + features[85:181]}\n",
    "}\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special data treatment for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = to_categorical(y_train.values, num_classes=3)\n",
    "y_val = to_categorical(y_val.values, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same architecture on all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "235470/235470 [==============================] - 61s 257us/step - loss: 11.2093 - acc: 0.2964\n",
      "Epoch 2/5\n",
      "235470/235470 [==============================] - 7s 31us/step - loss: 9.8606 - acc: 0.3206\n",
      "Epoch 3/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 8.9551 - acc: 0.3308\n",
      "Epoch 4/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 8.9359 - acc: 0.3325\n",
      "Epoch 5/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 8.9655 - acc: 0.3311\n",
      "26164/26164 [==============================] - 1s 39us/step\n",
      "Result for base_model: [11.2639201764502, 0.3009478673076907]\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "235470/235470 [==============================] - 7s 31us/step - loss: 9.1990 - acc: 0.3062\n",
      "Epoch 2/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 8.1490 - acc: 0.3238\n",
      "Epoch 3/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 8.1429 - acc: 0.3236\n",
      "Epoch 4/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 8.1748 - acc: 0.3217\n",
      "Epoch 5/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 8.1631 - acc: 0.3228\n",
      "26164/26164 [==============================] - 1s 40us/step\n",
      "Result for entropy_fft: [11.868644917599926, 0.2636447026448555]\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "235470/235470 [==============================] - 7s 31us/step - loss: 2.9873 - acc: 0.4164\n",
      "Epoch 2/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 1.0754 - acc: 0.4358\n",
      "Epoch 3/5\n",
      "235470/235470 [==============================] - 7s 29us/step - loss: 1.0749 - acc: 0.4358\n",
      "Epoch 4/5\n",
      "235470/235470 [==============================] - 7s 28us/step - loss: 1.0748 - acc: 0.4358\n",
      "Epoch 5/5\n",
      "235470/235470 [==============================] - 7s 28us/step - loss: 1.0748 - acc: 0.4358\n",
      "26164/26164 [==============================] - 1s 42us/step\n",
      "Result for dummy_variables_only: [1.0747486065513332, 0.4358660755145078]\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "235470/235470 [==============================] - 8s 34us/step - loss: 2.5067 - acc: 0.4171\n",
      "Epoch 2/5\n",
      "235470/235470 [==============================] - 8s 33us/step - loss: 1.0806 - acc: 0.4358\n",
      "Epoch 3/5\n",
      "235470/235470 [==============================] - 8s 34us/step - loss: 1.0753 - acc: 0.4358\n",
      "Epoch 4/5\n",
      "235470/235470 [==============================] - 8s 33us/step - loss: 1.0748 - acc: 0.4359\n",
      "Epoch 5/5\n",
      "235470/235470 [==============================] - 8s 33us/step - loss: 1.0749 - acc: 0.4358\n",
      "26164/26164 [==============================] - 1s 43us/step\n",
      "Result for dummy_variables: [1.0747563137298803, 0.4358660755145078]\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "235470/235470 [==============================] - 10s 41us/step - loss: 11.2494 - acc: 0.2747\n",
      "Epoch 2/5\n",
      "235470/235470 [==============================] - 9s 37us/step - loss: 11.2456 - acc: 0.2734\n",
      "Epoch 3/5\n",
      "235470/235470 [==============================] - 9s 37us/step - loss: 11.2491 - acc: 0.2730\n",
      "Epoch 4/5\n",
      "235470/235470 [==============================] - 9s 38us/step - loss: 11.2405 - acc: 0.2737\n",
      "Epoch 5/5\n",
      "235470/235470 [==============================] - 9s 39us/step - loss: 11.2484 - acc: 0.2734\n",
      "26164/26164 [==============================] - 1s 45us/step\n",
      "Result for fft_wawelets: [11.868644917599926, 0.2636447026448555]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "results = pd.DataFrame(columns=['model_name', 'loss', 'accuracy'])\n",
    "\n",
    "for model_name in equations:\n",
    "    predictors = equations[model_name]['predictors']\n",
    "\n",
    "    x_train = X_train[predictors].values\n",
    "    x_val = X_val[predictors].values\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(units=10, activation='relu', input_dim=x_train.shape[1]),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=10, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=10, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=3, activation='softmax'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    loss_and_metrics = model.evaluate(x_val, y_val)\n",
    "\n",
    "    print(\"Result for %s: %s\\n\\n\" % (model_name, loss_and_metrics))\n",
    "\n",
    "    results = results.append({\n",
    "        'model_name': model_name,\n",
    "        'loss': loss_and_metrics[0],\n",
    "        'accuracy': loss_and_metrics[1],\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_model</td>\n",
       "      <td>11.263920</td>\n",
       "      <td>0.300948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entropy_fft</td>\n",
       "      <td>11.868645</td>\n",
       "      <td>0.263645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummy_variables_only</td>\n",
       "      <td>1.074749</td>\n",
       "      <td>0.435866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummy_variables</td>\n",
       "      <td>1.074756</td>\n",
       "      <td>0.435866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fft_wawelets</td>\n",
       "      <td>11.868645</td>\n",
       "      <td>0.263645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name       loss  accuracy\n",
       "0            base_model  11.263920  0.300948\n",
       "1           entropy_fft  11.868645  0.263645\n",
       "2  dummy_variables_only   1.074749  0.435866\n",
       "3       dummy_variables   1.074756  0.435866\n",
       "4          fft_wawelets  11.868645  0.263645"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 10)                1780      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 2,033\n",
      "Trainable params: 2,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate curr_sleep 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df):\n",
    "    return train_test_split(df.loc[:, df.columns != var_to_pred],\n",
    "                            df[var_to_pred],\n",
    "                            test_size=0.10,\n",
    "                            random_state=0,\n",
    "                            stratify=df[var_to_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final_2 = df_train_final[ df_train_final[\"curr_sleep_stage_2.0\"] == 1 ]\n",
    "df_train_final_3 = df_train_final[ df_train_final[\"curr_sleep_stage_3.0\"] == 1 ]\n",
    "\n",
    "var_to_pred = 'SO'\n",
    "\n",
    "# Curr sleep 2\n",
    "X_train_2, X_val_2, y_train_2, y_val_2 = get_train_test_split(df_train_final_2)\n",
    "\n",
    "y_train_2 = to_categorical(pd.DataFrame(y_train_2).values, num_classes=3)\n",
    "y_val_2 = to_categorical(pd.DataFrame(y_val_2).values, num_classes=3)\n",
    "\n",
    "# Curr sleep 3\n",
    "X_train_3, X_val_3, y_train_3, y_val_3 = get_train_test_split(df_train_final_3)\n",
    "\n",
    "y_train_3 = to_categorical(pd.DataFrame(y_train_3).values, num_classes=3)\n",
    "y_val_3 = to_categorical(pd.DataFrame(y_val_3).values, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is 'fft_wawelets' (177 predictors)\n",
      "\n",
      "Epoch 1/60\n",
      "118229/118229 [==============================] - 3s 28us/step - loss: 6.9936 - acc: 0.5660\n",
      "Epoch 2/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.8364 - acc: 0.5758\n",
      "Epoch 3/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7924 - acc: 0.5786\n",
      "Epoch 4/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7846 - acc: 0.5791\n",
      "Epoch 5/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7806 - acc: 0.5793\n",
      "Epoch 6/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7801 - acc: 0.5794\n",
      "Epoch 7/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7810 - acc: 0.5793\n",
      "Epoch 8/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7812 - acc: 0.5793\n",
      "Epoch 9/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7816 - acc: 0.5793\n",
      "Epoch 10/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7814 - acc: 0.5793\n",
      "Epoch 11/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7808 - acc: 0.5793\n",
      "Epoch 12/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7809 - acc: 0.5793\n",
      "Epoch 13/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7814 - acc: 0.5793\n",
      "Epoch 14/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7813 - acc: 0.5793\n",
      "Epoch 15/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7809 - acc: 0.5793\n",
      "Epoch 16/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7814 - acc: 0.5793\n",
      "Epoch 17/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7806 - acc: 0.5793\n",
      "Epoch 18/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7806 - acc: 0.5793\n",
      "Epoch 19/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7808 - acc: 0.5793\n",
      "Epoch 20/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7803 - acc: 0.5793\n",
      "Epoch 21/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7806 - acc: 0.5793\n",
      "Epoch 22/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7801 - acc: 0.5794\n",
      "Epoch 23/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7805 - acc: 0.5793\n",
      "Epoch 24/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7808 - acc: 0.5793\n",
      "Epoch 25/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7808 - acc: 0.5793\n",
      "Epoch 26/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7802 - acc: 0.5793\n",
      "Epoch 27/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7798 - acc: 0.5794\n",
      "Epoch 28/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7816 - acc: 0.5793\n",
      "Epoch 29/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7817 - acc: 0.5792\n",
      "Epoch 30/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7813 - acc: 0.5793\n",
      "Epoch 31/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7816 - acc: 0.5793\n",
      "Epoch 32/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7818 - acc: 0.5792\n",
      "Epoch 33/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7821 - acc: 0.5792\n",
      "Epoch 34/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7816 - acc: 0.5793\n",
      "Epoch 35/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7823 - acc: 0.5792\n",
      "Epoch 36/60\n",
      "118229/118229 [==============================] - 2s 21us/step - loss: 6.7816 - acc: 0.5793\n",
      "Epoch 37/60\n",
      "118229/118229 [==============================] - 2s 21us/step - loss: 6.7805 - acc: 0.5793\n",
      "Epoch 38/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7813 - acc: 0.5793\n",
      "Epoch 39/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7821 - acc: 0.5792\n",
      "Epoch 40/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7818 - acc: 0.5792\n",
      "Epoch 41/60\n",
      "118229/118229 [==============================] - 2s 21us/step - loss: 6.7816 - acc: 0.5793\n",
      "Epoch 42/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7820 - acc: 0.5792\n",
      "Epoch 43/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7814 - acc: 0.5793\n",
      "Epoch 44/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7953 - acc: 0.5784\n",
      "Epoch 45/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7963 - acc: 0.5783\n",
      "Epoch 46/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7846 - acc: 0.5791\n",
      "Epoch 47/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7805 - acc: 0.5793\n",
      "Epoch 48/60\n",
      "118229/118229 [==============================] - 3s 22us/step - loss: 6.7805 - acc: 0.5793\n",
      "Epoch 49/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7805 - acc: 0.5793\n",
      "Epoch 50/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7802 - acc: 0.5793\n",
      "Epoch 51/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7808 - acc: 0.5793\n",
      "Epoch 52/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7805 - acc: 0.5793\n",
      "Epoch 53/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7807 - acc: 0.5793\n",
      "Epoch 54/60\n",
      "118229/118229 [==============================] - 2s 19us/step - loss: 6.7802 - acc: 0.5793\n",
      "Epoch 55/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7798 - acc: 0.5794\n",
      "Epoch 56/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7799 - acc: 0.5794\n",
      "Epoch 57/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7801 - acc: 0.5794\n",
      "Epoch 58/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7808 - acc: 0.5793\n",
      "Epoch 59/60\n",
      "118229/118229 [==============================] - 2s 20us/step - loss: 6.7808 - acc: 0.5793\n",
      "Epoch 60/60\n",
      "118229/118229 [==============================] - 2s 21us/step - loss: 6.7805 - acc: 0.5793\n",
      "Epoch 1/60\n",
      "117241/117241 [==============================] - 3s 29us/step - loss: 11.4258 - acc: 0.2911\n",
      "Epoch 2/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4261 - acc: 0.2911\n",
      "Epoch 3/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4253 - acc: 0.2912\n",
      "Epoch 4/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 5/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4262 - acc: 0.2911\n",
      "Epoch 6/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4254 - acc: 0.2911\n",
      "Epoch 7/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4257 - acc: 0.2911\n",
      "Epoch 8/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4258 - acc: 0.2911\n",
      "Epoch 9/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4257 - acc: 0.2911\n",
      "Epoch 10/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4254 - acc: 0.2911\n",
      "Epoch 11/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4261 - acc: 0.2911\n",
      "Epoch 12/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 13/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4258 - acc: 0.2911\n",
      "Epoch 14/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4261 - acc: 0.2911\n",
      "Epoch 15/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 16/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 17/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4254 - acc: 0.2911\n",
      "Epoch 18/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4250 - acc: 0.2912\n",
      "Epoch 19/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4258 - acc: 0.2911\n",
      "Epoch 20/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4258 - acc: 0.2911\n",
      "Epoch 21/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4253 - acc: 0.2912\n",
      "Epoch 22/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4254 - acc: 0.2911\n",
      "Epoch 23/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 24/60\n",
      "117241/117241 [==============================] - 2s 19us/step - loss: 11.4262 - acc: 0.2911\n",
      "Epoch 25/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4262 - acc: 0.2911\n",
      "Epoch 26/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4260 - acc: 0.2911\n",
      "Epoch 27/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 28/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4261 - acc: 0.2911\n",
      "Epoch 29/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4257 - acc: 0.2911\n",
      "Epoch 30/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 31/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4257 - acc: 0.2911\n",
      "Epoch 32/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4253 - acc: 0.2912\n",
      "Epoch 33/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4253 - acc: 0.2912\n",
      "Epoch 34/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4253 - acc: 0.2911\n",
      "Epoch 35/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 36/60\n",
      "117241/117241 [==============================] - 2s 19us/step - loss: 11.4250 - acc: 0.2912\n",
      "Epoch 37/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4253 - acc: 0.2911\n",
      "Epoch 38/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4258 - acc: 0.2911\n",
      "Epoch 39/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4253 - acc: 0.2912\n",
      "Epoch 40/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4256 - acc: 0.2911\n",
      "Epoch 41/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4257 - acc: 0.2911\n",
      "Epoch 42/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4258 - acc: 0.2911\n",
      "Epoch 43/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4240 - acc: 0.2912\n",
      "Epoch 44/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4250 - acc: 0.2912\n",
      "Epoch 45/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4249 - acc: 0.2912\n",
      "Epoch 46/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4255 - acc: 0.2911\n",
      "Epoch 47/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4162 - acc: 0.2917\n",
      "Epoch 48/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4225 - acc: 0.2913\n",
      "Epoch 49/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 11.4242 - acc: 0.2912\n",
      "Epoch 50/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4236 - acc: 0.2913\n",
      "Epoch 51/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.4251 - acc: 0.2912\n",
      "Epoch 52/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.3895 - acc: 0.2934\n",
      "Epoch 53/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 11.1511 - acc: 0.3081\n",
      "Epoch 54/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 10.6252 - acc: 0.3408\n",
      "Epoch 55/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 10.4190 - acc: 0.3536\n",
      "Epoch 56/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 10.4366 - acc: 0.3525\n",
      "Epoch 57/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 10.5261 - acc: 0.3469\n",
      "Epoch 58/60\n",
      "117241/117241 [==============================] - 2s 20us/step - loss: 10.7319 - acc: 0.3341\n",
      "Epoch 59/60\n",
      "117241/117241 [==============================] - 2s 21us/step - loss: 10.8876 - acc: 0.3245\n",
      "Epoch 60/60\n",
      "117241/117241 [==============================] - 3s 21us/step - loss: 10.9348 - acc: 0.3216\n",
      "13137/13137 [==============================] - 1s 69us/step\n",
      "13027/13027 [==============================] - 1s 67us/step\n",
      "\n",
      "Result for fft_wawelets (2): [6.779979903648785, 0.5793560173737092]\n",
      "Result for fft_wawelets (3): [11.425078104689307, 0.2911645044906732]\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "batch_size = 512\n",
    "\n",
    "model_name = \"fft_wawelets\"\n",
    "\n",
    "predictors = equations[model_name]['predictors']\n",
    "print(\"Model is '%s' (%d predictors)\\n\" % (model_name, len(predictors)))\n",
    "\n",
    "x_train_2 = X_train_2[predictors].values\n",
    "x_val_2 = X_val_2[predictors].values\n",
    "\n",
    "x_train_3 = X_train_3[predictors].values\n",
    "x_val_3 = X_val_3[predictors].values\n",
    "\n",
    "architecture = [\n",
    "    Dense(units=150, activation='relu', input_dim=x_train_2.shape[1]),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=100, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=60, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(units=30, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=3, activation='softmax'),\n",
    "]\n",
    "\n",
    "model_2 = Sequential(architecture)\n",
    "model_3 = Sequential(architecture)\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(x_train_2, y_train_2, epochs=epochs, batch_size=batch_size)\n",
    "model_3.fit(x_train_3, y_train_3, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "loss_and_metrics_2 = model_2.evaluate(x_val_2, y_val_2)\n",
    "loss_and_metrics_3 = model_3.evaluate(x_val_3, y_val_3)\n",
    "\n",
    "print(\"\\nResult for %s (2): %s\" % (model_name, loss_and_metrics_2))\n",
    "print(\"Result for %s (3): %s\" % (model_name, loss_and_metrics_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Epochs=5, batch_size=128\n",
    "\n",
    "2: 0.579\n",
    "\n",
    "3: 0.368\n",
    "\n",
    "\n",
    "##### Epochs=60, batch_size=512\n",
    "\n",
    "2: 0.233\n",
    "\n",
    "3: 0.368"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original dataset (NO NEED TO RE-RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_columns(df):\n",
    "    l_columns = [\n",
    "        'num_pso', \n",
    "        'mean_amp_pso',\n",
    "        'mean_dur_pso',\n",
    "        'amp_cso',\n",
    "        'dur_cso',\n",
    "        'curr_sleep_stage',\n",
    "        'time_since_sleep',\n",
    "        'time_in_ds',\n",
    "        'time_in_ls',\n",
    "        'time_in_rs',\n",
    "        'time_in_ws',\n",
    "    ]\n",
    "\n",
    "    for i in range(12, 1261+1):\n",
    "        l_columns.append('eeg_signal_%s' % (i - 12 + 1))\n",
    "\n",
    "    df.columns = l_columns\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pso</th>\n",
       "      <th>mean_amp_pso</th>\n",
       "      <th>mean_dur_pso</th>\n",
       "      <th>amp_cso</th>\n",
       "      <th>dur_cso</th>\n",
       "      <th>curr_sleep_stage</th>\n",
       "      <th>time_since_sleep</th>\n",
       "      <th>time_in_ds</th>\n",
       "      <th>time_in_ls</th>\n",
       "      <th>time_in_rs</th>\n",
       "      <th>...</th>\n",
       "      <th>eeg_signal_1241</th>\n",
       "      <th>eeg_signal_1242</th>\n",
       "      <th>eeg_signal_1243</th>\n",
       "      <th>eeg_signal_1244</th>\n",
       "      <th>eeg_signal_1245</th>\n",
       "      <th>eeg_signal_1246</th>\n",
       "      <th>eeg_signal_1247</th>\n",
       "      <th>eeg_signal_1248</th>\n",
       "      <th>eeg_signal_1249</th>\n",
       "      <th>eeg_signal_1250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237.0</td>\n",
       "      <td>152.658761</td>\n",
       "      <td>341.523207</td>\n",
       "      <td>128.017491</td>\n",
       "      <td>429.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11379.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.707487</td>\n",
       "      <td>15.042639</td>\n",
       "      <td>9.706864</td>\n",
       "      <td>7.305480</td>\n",
       "      <td>5.344436</td>\n",
       "      <td>2.674903</td>\n",
       "      <td>-0.055816</td>\n",
       "      <td>-1.212385</td>\n",
       "      <td>-2.461937</td>\n",
       "      <td>-4.930397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176.0</td>\n",
       "      <td>146.883435</td>\n",
       "      <td>338.039773</td>\n",
       "      <td>119.130849</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6721.0</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.839801</td>\n",
       "      <td>3.458973</td>\n",
       "      <td>4.441102</td>\n",
       "      <td>3.975107</td>\n",
       "      <td>1.000240</td>\n",
       "      <td>2.870631</td>\n",
       "      <td>7.071897</td>\n",
       "      <td>7.848365</td>\n",
       "      <td>4.033517</td>\n",
       "      <td>-2.110046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>456.0</td>\n",
       "      <td>152.376541</td>\n",
       "      <td>335.629386</td>\n",
       "      <td>164.292580</td>\n",
       "      <td>417.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26832.0</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>7440.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.093293</td>\n",
       "      <td>22.821611</td>\n",
       "      <td>14.196937</td>\n",
       "      <td>5.708701</td>\n",
       "      <td>-0.753271</td>\n",
       "      <td>-5.627993</td>\n",
       "      <td>-9.804085</td>\n",
       "      <td>-12.863908</td>\n",
       "      <td>-11.951175</td>\n",
       "      <td>-5.531799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>139.720772</td>\n",
       "      <td>336.285714</td>\n",
       "      <td>159.237082</td>\n",
       "      <td>407.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.191571</td>\n",
       "      <td>25.032295</td>\n",
       "      <td>17.296456</td>\n",
       "      <td>6.335396</td>\n",
       "      <td>-4.008689</td>\n",
       "      <td>-8.589818</td>\n",
       "      <td>-5.876062</td>\n",
       "      <td>0.166707</td>\n",
       "      <td>6.054539</td>\n",
       "      <td>12.086351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>140.649432</td>\n",
       "      <td>349.875000</td>\n",
       "      <td>130.184278</td>\n",
       "      <td>297.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.942308</td>\n",
       "      <td>-10.407617</td>\n",
       "      <td>-3.418883</td>\n",
       "      <td>9.222596</td>\n",
       "      <td>21.236168</td>\n",
       "      <td>28.245889</td>\n",
       "      <td>27.024864</td>\n",
       "      <td>17.794644</td>\n",
       "      <td>7.602379</td>\n",
       "      <td>-4.548318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pso  mean_amp_pso  mean_dur_pso     amp_cso  dur_cso  curr_sleep_stage  \\\n",
       "0    237.0    152.658761    341.523207  128.017491    429.0               3.0   \n",
       "1    176.0    146.883435    338.039773  119.130849    196.0               2.0   \n",
       "2    456.0    152.376541    335.629386  164.292580    417.0               2.0   \n",
       "3     21.0    139.720772    336.285714  159.237082    407.0               3.0   \n",
       "4     72.0    140.649432    349.875000  130.184278    297.0               3.0   \n",
       "\n",
       "   time_since_sleep  time_in_ds  time_in_ls  time_in_rs  ...  eeg_signal_1241  \\\n",
       "0           11379.0      2730.0      3780.0         0.0  ...        22.707487   \n",
       "1            6721.0      2580.0      2100.0         0.0  ...         2.839801   \n",
       "2           26832.0      3240.0      7440.0      2130.0  ...        27.093293   \n",
       "3            1289.0         0.0        60.0         0.0  ...        28.191571   \n",
       "4            2262.0       630.0       960.0         0.0  ...        -7.942308   \n",
       "\n",
       "   eeg_signal_1242  eeg_signal_1243  eeg_signal_1244  eeg_signal_1245  \\\n",
       "0        15.042639         9.706864         7.305480         5.344436   \n",
       "1         3.458973         4.441102         3.975107         1.000240   \n",
       "2        22.821611        14.196937         5.708701        -0.753271   \n",
       "3        25.032295        17.296456         6.335396        -4.008689   \n",
       "4       -10.407617        -3.418883         9.222596        21.236168   \n",
       "\n",
       "   eeg_signal_1246  eeg_signal_1247  eeg_signal_1248  eeg_signal_1249  \\\n",
       "0         2.674903        -0.055816        -1.212385        -2.461937   \n",
       "1         2.870631         7.071897         7.848365         4.033517   \n",
       "2        -5.627993        -9.804085       -12.863908       -11.951175   \n",
       "3        -8.589818        -5.876062         0.166707         6.054539   \n",
       "4        28.245889        27.024864        17.794644         7.602379   \n",
       "\n",
       "   eeg_signal_1250  \n",
       "0        -4.930397  \n",
       "1        -2.110046  \n",
       "2        -5.531799  \n",
       "3        12.086351  \n",
       "4        -4.548318  \n",
       "\n",
       "[5 rows x 1261 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "y_train = pd.read_csv(\"original_data/y_train.csv\").values[:, 1].squeeze()\n",
    "X_train = h5py.File(\"original_data/X_train.h5\", \"r\")\n",
    "\n",
    "df_train = pd.DataFrame(data=X_train[\"features\"][:])\n",
    "label_columns(df_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_hdf('df_train.h5', key='df_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_hdf('df_train.h5', 'df_train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
